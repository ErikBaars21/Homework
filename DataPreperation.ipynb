{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf337163",
   "metadata": {},
   "source": [
    "# Team 7 Project - Yellow Taxi Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197a96e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [Imports](#2.-Imports)\n",
    "3. [Data-Preperation](#3.-Data-Preperation)\n",
    "    - [3.1 Weather-Dataset](#3.1-Clean-up-of-the-Weather-Data-Set)\n",
    "    - [3.2 Taxi-Dataset](#3.2-Clean-up-of-the-Yellow-Taxi-Data-Set)\n",
    "    - [3.3 Taxi-Zones](#3.3-Clean-up-of-the-Taxi-Zones)\n",
    "    - [3.4 Merged Zones + Trip](#3.4-Merge-of-zones-and-trips)\n",
    "    - [3.5 Merge of Weather + Trip](#3.5-Merge-of-weather-and-trips)\n",
    "    - [3.6 Model Specific Feature-Engineering](#3.6-Model-Specific-Feature-Engineering)\n",
    "4. [Descriptive Analysis](#4.-Descriptive-Analysis)\n",
    "    - [4.1 Temperature](#4.1-Number-of-rides-according-to-the-temperature)\n",
    "    - [4.2 Common Pickup-Zones](#4.2-Most-Common-Pickup-Zones)\n",
    "        - [4.2.1 Common Pickup Heatmap](#4.2.1-Heatmap)\n",
    "    - [4.3 Common Dropoff-Zones](#4.3-Most-Common-Dropoff-Zones)\n",
    "    - [4.4 Most Common Pairs](#4.4-Most-Common-Pairs)\n",
    "    - [4.5 Temporal Trip Patterns](#4.4-Temporal-Trip-Patterns)\n",
    "        - [4.5.1 Time-of-Day Usage](#4.5.1-Time-of-Day-Usage)\n",
    "        - [4.5.2 Day-of-Week Usage](#4.5.2-Day-of-Week-Usage)\n",
    "5. [Predictive Models](#5.-Predictive-Models)\n",
    "    - [5.1 Random Forrest Regression](#5.1-Random-Forrest-Regression)\n",
    "        - [5.1.1 Data-Split](#5.1.1-Data-Split)\n",
    "        - [5.1.2 Target Encoding](#5.1.2-Target-Encoding)\n",
    "        - [5.1.2 Hyper-Parameter Optimization](#5.1.3-Hyper-Parameter-Optimization)\n",
    "        - [5.1.4 Model-Training and Testing](#5.1.4-Model-Training-and-Testing)\n",
    "        - [5.1.5 Visualisation](#5.1.5-Visualisation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28b1db",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "For our team project, we have chosen to analyze the <a href=\"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\">NYC Yellow Taxi Dataset January (2021)</a>, which contains collected data of taxi trips in New York City. The dataset offers information such as pickup and drop-off times, trip distances, fares, passenger counts, and various surcharges. In the following, we will point out, which features we are going to include and which target we are going to predict.\n",
    "\n",
    "\n",
    "## Context and Relevance\n",
    "\n",
    "Understanding trip counts provides valuable insights for various stakeholders:\n",
    "* Shared `mobility providers` can use demand patterns to optimize fleet allocation, predict peak times, and identify opportunities for new services\n",
    "* City `governments` can leverage this data to improve traffic management, urban planning, and environmental policies by understanding when and where taxi demand is highest\n",
    "* For `society` at large, improved knowledge of taxi usage contributes to more efficient transportation networks, reduced congestion and emissions, and better mobility services for residents and visitors\n",
    "\n",
    "The primary goal of this analysis is to identify temporal and spatial patterns in taxi demand through trip count metrics. Key questions include:\n",
    "\n",
    "* Are there weather trends in the trip data?\n",
    "* Which neighborhoods have the most frequent taxi activity?\n",
    "* Are there any Temporal Trends?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d8202",
   "metadata": {},
   "source": [
    "## *2. Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67397bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d29af",
   "metadata": {},
   "source": [
    "## 3. Data-Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01491779",
   "metadata": {},
   "source": [
    "### *3.1 Clean-up of the Weather Data-Set*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2837f4",
   "metadata": {},
   "source": [
    "The utilized raw dataset contains historical weather data with the following columns:\n",
    "\n",
    "* `time`: Timestamp of the recorded data (e.g., hourly or daily).\n",
    "\n",
    "* `temperature_2m (°C)`: Air temperature measured at 2 meters above ground level, in degrees Celsius.\n",
    "\n",
    "* `precipitation (mm)`: Total amount of precipitation, in millimeters.\n",
    "\n",
    "* `rain (mm)`: Rainfall amount specifically, in millimeters.\n",
    "\n",
    "* `cloudcover (%)`: Total cloud coverage, expressed as a percentage.\n",
    "\n",
    "* `cloudcover_low (%)`: Low-altitude cloud coverage, in percent.\n",
    "\n",
    "* `cloudcover_mid (%)`: Mid-altitude cloud coverage, in percent.\n",
    "\n",
    "* `cloudcover_high (%)`: High-altitude cloud coverage, in percent.\n",
    "\n",
    "* `windspeed_10m (km/h)`: Wind speed measured at 10 meters above ground, in kilometers per hour.\n",
    "\n",
    "* `winddirection_10m (°)`: Wind direction at 10 meters above ground, in degrees (0–360°).\n",
    "\n",
    "This dataset provides a comprehensive view of atmospheric conditions and is suitable for analyzing weather patterns, forecasting, or climate trend detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69957ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('NYC_Weather_2016_2022.csv')\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02532534",
   "metadata": {},
   "source": [
    "In our <a href=\"https://www.kaggle.com/datasets/aadimator/nyc-weather-2016-to-2022?resource=download\">NYC Weather Dataset</a>, we initially filtered out all data that does not pertain to January 2021, since our primary dataset is also focused exclusively on that month.\n",
    "\n",
    "Also we dropped some columns because of their limited relevance for our predictive tasks:\n",
    "\n",
    "* `cloudcover (%)`\n",
    "* `cloudcover_low (%)`\n",
    "* `cloudcover_mid (%)`\n",
    "* `cloudcover_high (%)`\n",
    "* `winddirection_10m (°)`\n",
    "\n",
    "All of the cloud cover levels do only have minimal impact on taxi demand or passenger behavior. Since it tends to correlate with other more impactful weather features such as precipitation and temperature, it does not provide significant added value for our models. <br>\n",
    "`winddirection` also wont influence the taxi patterns in a meaningful way within an urban environtment like NYC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5356a90-9612-4c46-a609-9207d9d853d5",
   "metadata": {},
   "source": [
    "#### weather = weather.loc[weather['time'].str[:7] == \"2021-01\"].copy()\n",
    "weather['time'] = pd.to_datetime(weather['time'])\n",
    "\n",
    "columns_to_drop = [\n",
    "    'cloudcover (%)',\n",
    "    'cloudcover_low (%)',\n",
    "    'cloudcover_mid (%)',\n",
    "    'cloudcover_high (%)',\n",
    "    'winddirection_10m (°)'\n",
    "]\n",
    "weather = weather.drop(columns=columns_to_drop)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dd4639",
   "metadata": {},
   "source": [
    "### *3.2 Clean-up of the Yellow Taxi Data-Set* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dca031",
   "metadata": {},
   "source": [
    "NYC Yellow Taxi Trip Records\n",
    "This dataset contains detailed information on individual yellow taxi trips in New York City, including:\n",
    "\n",
    "* `VendorID`: Taxi company/provider identifier.\n",
    "\n",
    "* `tpep_pickup_datetime / tpep_dropoff_datetime`: Timestamps for pickup and drop-off.\n",
    "\n",
    "* `passenger_count`: Number of passengers.\n",
    "\n",
    "* `trip_distance`: Distance of the trip in miles.\n",
    "\n",
    "* `RatecodeID`: Fare rate code (e.g., standard rate, JFK flat fare).\n",
    "\n",
    "* `store_and_fwd_flag`: Indicates if the trip record was stored in the taxi’s memory before being sent (Y/N).\n",
    "\n",
    "* `PULocationID / DOLocationID`: Pickup and drop-off location codes (mapped to taxi zones).\n",
    "\n",
    "* `payment_type`: Type of payment (e.g., credit card, cash).\n",
    "\n",
    "* `fare_amount`, `extra`, `mta_tax`, `tip_amount`, `tolls_amount`, `improvement_surcharge`, `total_amount`: Fare breakdown.\n",
    "\n",
    "* `congestion_surcharge / airport_fee`: Additional surcharges related to traffic zones and airport trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b55c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData = pd.read_parquet('yellow_tripdata_2021-01.parquet', engine='pyarrow')\n",
    "TripData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49377a34",
   "metadata": {},
   "source": [
    " #### The following columns have been removed: \n",
    " * `store_and_fwd_flag`\n",
    " * `airport_fee`\n",
    " * `RatecodeID`\n",
    " * `payment_type`\n",
    " * `fare_amount`\n",
    " * `extra`\n",
    " * `mta_tax`\n",
    " * `tip_amount`\n",
    " * `tolls_amount`\n",
    " * `improvement_surcharge`\n",
    " * `total_amount`\n",
    " * `congestion_surcharge`\n",
    " \n",
    " \n",
    "The `store_and_fwd_flag column` indicates whether the trip record was temporarily stored in the vehicle's memory before being sent to the vendor, also known as \"store and forward,\" due to the vehicle's lack of server connectivity at the time of the trip. Since this information does not contribute to our analysis, we decided to exclude this column. \n",
    "<br>\n",
    "`VendorID`, `payment_type`, `airport_fee`, `fare_amount`, `extra`, `mta_tax`, `tip_amount`, `tolls_amount`, `improvement_surcharge`, `total_amount`, `congestion_surcharge` all represent detailed financial components of each trip. While useful for fare analysis or revenue modeling, they are not required for understanding the frequency or distribution of trips. Consequently, we decided to drop these columns to simplify the dataset and focus solely on trip counts.\n",
    "<br>\n",
    "\n",
    "#### The following rows have been removed:\n",
    "\n",
    "All rows containing 'NaN' <br>\n",
    "\n",
    "For further information, please refer to the <a href=\"https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\">Yellow Taxi Data Dictonary</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'store_and_fwd_flag',\n",
    "    'airport_fee',\n",
    "    'RatecodeID',\n",
    "    'payment_type',\n",
    "    'fare_amount',\n",
    "    'extra',\n",
    "    'mta_tax',\n",
    "    'tip_amount',\n",
    "    'tolls_amount',\n",
    "    'improvement_surcharge',\n",
    "    'total_amount',\n",
    "    'congestion_surcharge',\n",
    "    'VendorID'\n",
    "]\n",
    "\n",
    "\n",
    "TripData.drop(columns=cols_to_drop, inplace=True)\n",
    "TripData = TripData.dropna()\n",
    "\n",
    "\n",
    "TripData = TripData.copy() ## Added for SettingWithCopyWarning\n",
    "\n",
    "TripData['PULocationID'] = TripData['PULocationID'].astype(int) ## Checking if LocationIDs are Integers\n",
    "TripData['DOLocationID'] = TripData['DOLocationID'].astype(int)\n",
    "\n",
    "\n",
    "TripData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2639c72",
   "metadata": {},
   "source": [
    "Since one of our future prediction tasks requires the duration of the trip, we have added a new column, `trip_time_minutes`, by subtracting the `tpep_pickup_datetime` from the `tpep_dropoff_datetime`. We also resorted the dataset so that the trip duration appears after the pickup and drop-off columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the trip time in minutes\n",
    "TripData['trip_time_minutes'] = (TripData['tpep_dropoff_datetime'] - TripData['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Resorting the dataset and insert trip time behind pu/do \n",
    "col = TripData.pop('trip_time_minutes')\n",
    "TripData.insert(3, 'trip_time_minutes', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe498c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5afaa",
   "metadata": {},
   "source": [
    "### *3.3 Clean-up of the Taxi-Zones*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a523a8",
   "metadata": {},
   "source": [
    "This dataset contains metadata for geographic taxi zones used in trip records:\n",
    "\n",
    "* `location_id`: Numeric identifier for each zone (matches PULocationID and DOLocationID in trip data).\n",
    "\n",
    "* `zone`: Name of the taxi zone (e.g., \"Upper East Side North\", \"JFK Airport\").\n",
    "\n",
    "* `borough`: Borough the zone is in (e.g., \"Manhattan\", \"Brooklyn\").\n",
    "\n",
    "* `shape_area` / shape_leng: Geometric area and perimeter length of the zone.\n",
    "\n",
    "* `objectid`: Internal object identifier (not typically used in analysis).\n",
    "\n",
    "* `geometry`: Spatial polygon data defining the zone's shape (used for mapping/visualization).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file(\"NYC Taxi Zones.geojson\")\n",
    "zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38837c70",
   "metadata": {},
   "source": [
    "To analyse common pick up and drop off locations in the future, we have also added the `NYC Taxi Zones` Dataset. We dropped `shape_area`, `objectid` and `shape_leng` since we dont need this information in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = zones[['location_id', 'zone', 'borough', 'geometry']].copy()\n",
    "zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd45c2",
   "metadata": {},
   "source": [
    "### *3.4 Merge of zones and trips*\n",
    "\n",
    "To analyse demand in certain areas later, we will merge `zones`  with the `TripData` <br>\n",
    "\n",
    "\n",
    "Since we dont need most of the columns from our `TripData` Dataset, we only included a few. Also we renamed certain columns for clarity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = zones.rename(columns={'location_id': 'LocationID'})\n",
    "\n",
    "zones['LocationID'] = zones['LocationID'].astype(int)           ## The PU/DOLocations where int64, while \n",
    "TripData['PULocationID'] = TripData['PULocationID'].astype(int) ## LocationID had the type object\n",
    "TripData['DOLocationID'] = TripData['DOLocationID'].astype(int) ## so change both to int64\n",
    "\n",
    "TripData_zones = TripData.merge(                                ## merge pickup\n",
    "    zones[['LocationID', 'zone', 'borough', 'geometry']],\n",
    "    left_on='PULocationID',\n",
    "    right_on='LocationID',\n",
    "    how='left',\n",
    "    suffixes=('', '_pickup')\n",
    ")\n",
    "\n",
    "TripData_zones = TripData_zones.merge(                          ## merge dropoff\n",
    "    zones[['LocationID', 'zone', 'borough', 'geometry']],\n",
    "    left_on='DOLocationID',\n",
    "    right_on='LocationID',\n",
    "    how='left',\n",
    "    suffixes=('', '_dropoff')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripZones = TripData_zones.rename(columns={               ## rename\n",
    "    'zone': 'pickup_zone',\n",
    "    'borough': 'pickup_borough',\n",
    "    'geometry': 'pickup_geometry',\n",
    "    'geometry_dropoff': 'dropoff_geometry'\n",
    "})\n",
    "\n",
    "TripZones = TripZones[[                              ## resort + drop certain columns\n",
    "    'passenger_count',\n",
    "    'tpep_pickup_datetime',\n",
    "    'pickup_zone',\n",
    "    'pickup_borough',\n",
    "    'pickup_geometry',\n",
    "    'tpep_dropoff_datetime',\n",
    "    'zone_dropoff',\n",
    "    'borough_dropoff',\n",
    "    'dropoff_geometry'\n",
    "]]\n",
    "\n",
    "TripZones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b223210",
   "metadata": {},
   "source": [
    "### *3.5 Merge of weather and trips*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c13f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData['tpep_pickup_datetime'] = TripData['tpep_pickup_datetime'].astype('datetime64[ns]')\n",
    "weather['time'] = weather['time'].astype('datetime64[ns]')\n",
    "\n",
    "TripData_sorted = TripData.sort_values('tpep_pickup_datetime')\n",
    "weather_sorted = weather.sort_values('time')\n",
    "\n",
    "TripData_weather = pd.merge_asof(\n",
    "    TripData_sorted,\n",
    "    weather_sorted[['time', 'temperature_2m (°C)', 'rain (mm)']],\n",
    "    left_on='tpep_pickup_datetime',\n",
    "    right_on='time',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "TripData_weather = TripData_weather.dropna()\n",
    "TripData_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e732f4",
   "metadata": {},
   "source": [
    "### 3.6 Model Specific Feature-Engineering\n",
    "To ensure a clear separation between descriptive analysis and predictive modeling, we created a dedicated DataFrame that contains only the features relevant for modeling purposes. The modeling DataFrame is based on a temporal and spatial aggregation of the trip data. First, all pickup timestamps (tpep_pickup_datetime) were rounded down to 30-minute intervals. Then, the data was grouped by both the pickup time and the pickup location (PULocationID). Within each group, we computed: the number of trips (trip_count), the average temperature (temperature_2m (°C)), and the average precipitation (rain (mm)). Additional features such as hour and weekday were extracted from the rounded timestamps to capture time-of-day and weekly patterns. The final set of explanatory variables used in the model includes: temperature_2m (°C), rain (mm), hour, weekdayand PULocationID The target variable is trip_count, representing the number of trips observed for a given pickup location and 30-minute time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData_weather['tpep_pickup_datetime'] = TripData_weather['tpep_pickup_datetime'].dt.floor('30min') #Roudning the timestamps\n",
    "stats = ( \n",
    "    TripData_weather\n",
    "    .groupby(['tpep_pickup_datetime', 'PULocationID'])\n",
    "    .agg({\n",
    "        'temperature_2m (°C)': 'mean',\n",
    "        'rain (mm)': 'mean',\n",
    "        'tpep_pickup_datetime': 'count'\n",
    "    })\n",
    "    .rename(columns={'tpep_pickup_datetime': 'trip_count'})\n",
    "    .reset_index()\n",
    ")\n",
    "stats['hour'] = stats['tpep_pickup_datetime'].dt.hour #Creating hour column\n",
    "stats['weekday'] = stats['tpep_pickup_datetime'].dt.weekday #Creating Weekday Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163b8b9-239b-497c-870d-6538301608c6",
   "metadata": {},
   "source": [
    "#### 3.6.1 Rollling Means\n",
    "We implemented a rolling mean feature, which contains the average Tripcount for a zone from the last 2 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d72aa1-9842-41ce-8a95-190fb7bbc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.sort_values(['PULocationID', 'tpep_pickup_datetime'])\n",
    "stats['rolling_mean_2h'] = (\n",
    "    stats.groupby('PULocationID')['trip_count']\n",
    "    .transform(lambda x: x.rolling(window=4, min_periods=1).mean().shift(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ec8ed",
   "metadata": {},
   "source": [
    "## 4. Descriptive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2947a9",
   "metadata": {},
   "source": [
    "### 4.1 Number of rides according to the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb67634",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData_weather['temperature_rounded'] = TripData_weather['temperature_2m (°C)'].round()\n",
    "\n",
    "temp_group = TripData_weather.groupby('temperature_rounded').size().reset_index(name='ride_count')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(temp_group['temperature_rounded'], temp_group['ride_count'], marker='o')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.title('Number of Taxi Rides vs Temperature')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d21541d",
   "metadata": {},
   "source": [
    "This line plot illustrates the relationship between temperature (°C) and the number of taxi rides. The number of rides peaks sharply in the range [-1°C and 4°C,], suggesting that people heavily rely on taxis when it's cold but not extreme—likely to avoid discomfort while still being mobile. \n",
    "For very low temperatures [< -1°C], ride numbers are lower, possibly due to reduced outdoor activity in harsh cold. From, mild to warm temperatures [4 °C to 10°C], a noticeable drop in taxi rides is observed. Warmer conditions may encourage walking, biking, or using public transport instead.\n",
    "Taxi demand is highest around freezing temperatures, indicating weather sensitivity. People are more likely to choose taxis when it's cold enough to be uncomfortable, but not cold enough to deter travel altogether.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e1f26",
   "metadata": {},
   "source": [
    "### 4.2 Most Common Pickup-Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_counts = TripZones.groupby('pickup_zone').size().reset_index(name='pickup_count')\n",
    "pickup_counts = pickup_counts.sort_values(by='pickup_count', ascending=False)\n",
    "\n",
    "print(pickup_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=pickup_counts.head(10),\n",
    "    y='pickup_count',\n",
    "    x='pickup_zone',\n",
    "    hue='pickup_zone',\n",
    "    palette='Oranges_r',\n",
    "    legend=False\n",
    ")\n",
    "plt.title('Top 10 Pickup-Zones')\n",
    "plt.ylabel('Trip Count')\n",
    "plt.xlabel('Pickup-Zone')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1766cb5",
   "metadata": {},
   "source": [
    "This horizontal bar chart displays the top 10 taxi pickup zones based on trip volume. It reveals a right-skewed frequency distribution, with the first two zones (Upper East Side North and Upper East Side South) dominating the dataset (around 72,000+ trips each). This suggests a high concentration of demand in these zones. Zones ranked 3 to 10 show a gradual decline in trip count, ranging from around 45,000 to around 40,000 trips. The slope is relatively flat, indicating that these zones have comparable levels of demand, forming a plateau below the top two.\n",
    "Many zones belong to Manhattan’s densely populated or commercial areas (e.g., Midtown, Lenox Hill, Penn Station), which likely reflects high pedestrian traffic, tourism, and business activity.\n",
    "The Upper East Side accounts for a disproportionate share of ride activity, signalling potential hotspots for taxi availability, resource allocation, or pricing optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859afa8d",
   "metadata": {},
   "source": [
    "#### 4.2.1 Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd86683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickup_zone_stats = TripZones.groupby(\n",
    "    ['pickup_zone', 'pickup_geometry']\n",
    ").size().reset_index(name='count')\n",
    "\n",
    "pickup_zone_stats = gpd.GeoDataFrame(pickup_zone_stats, geometry='pickup_geometry')\n",
    "\n",
    "pickup_zone_stats.plot(\n",
    "    column='count',\n",
    "    cmap='OrRd',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    legend=True,\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.title('Heatmap: Trip count per Pickup Zone')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2efb32",
   "metadata": {},
   "source": [
    "The heatmap confirms a strong spatial concentration of pickups in central Manhattan, especially the Upper East Side and Midtown. These zones show the highest intensity (70,000+ rides), while outer boroughs display significantly lower demand. The distribution is highly clustered, reflecting dense population, tourism, and commercial activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f0e3c",
   "metadata": {},
   "source": [
    "### 4.3 Most Common Dropoff-Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f859ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoff_counts = TripZones.groupby('zone_dropoff').size().reset_index(name='dropoff_count')\n",
    "dropoff_counts = dropoff_counts.sort_values(by='dropoff_count', ascending=False)\n",
    "\n",
    "print(dropoff_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca4e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=dropoff_counts.head(10),\n",
    "    y='dropoff_count',\n",
    "    x='zone_dropoff',\n",
    "    hue='zone_dropoff',\n",
    "    palette='Blues_r',\n",
    "    legend=False\n",
    ")\n",
    "plt.title('Top 10 Drop-Off-Zones')\n",
    "plt.ylabel('Trip Count')\n",
    "plt.xlabel('Drop-Off-Zone')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a2d96",
   "metadata": {},
   "source": [
    "This bar chart ranks the top 10 drop-off zones by total trip count. The same two zones again lead the distribution, with Upper East Side North peaking at over 70,000 drop-offs. This mirrors the pickup pattern, indicating bidirectional demand concentration.\n",
    "The remaining zones form a moderately flat tail, ranging between around 34,000 and around 43,000 trips. This suggests a more uniform distribution of drop-offs beyond the primary hotspots. Drop-off activity is heavily concentrated in a few zones—especially the Upper East Side—indicating consistent inbound and outbound flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e1448",
   "metadata": {},
   "source": [
    "### 4.4 Most Common Pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ce57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = TripZones.groupby(['pickup_zone', 'zone_dropoff']).size().reset_index(name='trip_count')\n",
    "top_10 = pair_counts.sort_values(by='trip_count', ascending=False).head(10)\n",
    "\n",
    "top_10['pair'] = top_10['pickup_zone'] + \" → \" + top_10['zone_dropoff']\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(top_10['pair'], top_10['trip_count'], color='skyblue')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{int(height)}',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3),  # offset text upward\n",
    "                 textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.title('Top 10 Most Common Pickup → Dropoff Zone Pairs')\n",
    "plt.xlabel('Pickup → Dropoff Pair')\n",
    "plt.ylabel('Trip Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101d2a7",
   "metadata": {},
   "source": [
    "This bar chart ranks the most frequent pickup/drop-off pairs by trip volume. The top 4 pairs are all within the Upper East Side, indicating a high volume of short, local trips—likely driven by dense population and limited walkability or convenience. The leading pair (UES South -> UES North) alone accounts for over 11,600 trips, showing a steep drop-off beyond the top few pairs. This suggests localized mobility clusters.\n",
    "Taxi usage is largely intra-neighborhood, especially within the Upper East Side, pointing to localized, short-distance travel behavior in dense urban zones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200819e",
   "metadata": {},
   "source": [
    "### 4.5 Temporal Trip Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c062c8",
   "metadata": {},
   "source": [
    "#### 4.5.1 Time-of-Day Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14653692",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData['tpep_pickup_datetime'] = pd.to_datetime(TripData['tpep_pickup_datetime'])\n",
    "\n",
    "TripData['pickup_hour'] = TripData['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "trips_per_hour = TripData.groupby('pickup_hour').size().reset_index(name='trip_count')\n",
    "\n",
    "trips_per_hour = trips_per_hour.sort_values('pickup_hour')\n",
    "\n",
    "print(trips_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb86de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(trips_per_hour['pickup_hour'], trips_per_hour['trip_count'], color='skyblue')\n",
    "plt.xlabel('Daytime')\n",
    "plt.ylabel('Trip Count')\n",
    "plt.title('Tripcount per hour of the day')\n",
    "plt.xticks(range(0,24))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa4dfd",
   "metadata": {},
   "source": [
    "This bar chart displays hourly taxi demand over a 24-hour period. Trip volume peaks sharply between 1 PM and 4 PM, with a maximum of 106,000 rides at 3 PM, suggesting a high concentration of afternoon activity, possibly driven by shopping, work breaks, or school pickups. Ride volume remains low overnight, with a gradual ramp-up starting around 6 AM.\n",
    "The demand curve is right-skewed, with the bulk of trips occurring between late morning and early evening, indicating a strong diurnal pattern tied to urban daytime activity cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee86082",
   "metadata": {},
   "source": [
    "#### 4.5.2 Day-of-Week Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253765d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TripData['tpep_pickup_datetime'] = pd.to_datetime(TripData['tpep_pickup_datetime'])\n",
    "\n",
    "TripData['pickup_weekday'] = TripData['tpep_pickup_datetime'].dt.dayofweek\n",
    "\n",
    "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "TripData['weekday_name'] = TripData['pickup_weekday'].apply(lambda x: weekday_names[x])\n",
    "\n",
    "TripData['weekday_name'] = pd.Categorical(\n",
    "    TripData['weekday_name'],\n",
    "    categories=weekday_names,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "trips_per_weekday = TripData.groupby('weekday_name', observed=True).size().reset_index(name='trip_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524388d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(trips_per_weekday['weekday_name'], trips_per_weekday['trip_count'], color='seagreen')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Tripcount')\n",
    "plt.title('Number of Trips per Weekday')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88355416",
   "metadata": {},
   "source": [
    "This bar chart shows the distribution of trip counts by day of the week. Friday records the highest trip volume, suggesting increased end-of-week activity—commuting, social plans, or travel. Monday to Friday show consistently higher demand than Saturday and Sunday, pointing to a weekday-dominant usage trend, likely tied to work-related or routine travel. Finally, trip count dips significantly after Friday, making Sunday the least active day in terms of taxi usage.\n",
    "Taxi demand follows a weekly cycle, peaking on Fridays and declining over the weekend, reflecting typical urban mobility rhythms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce9daa",
   "metadata": {},
   "source": [
    "## 5. Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c3f38",
   "metadata": {},
   "source": [
    "### 5.1 Random Forrest Regression\n",
    "In our first model, we used a Random Forest Regression model to predict the number of taxi rides within a 30-minute time frame in a specific zone. The target variable is `trip_count`, and the explanatory features are `temperature_2m (°C)`, `rain (mm)`, `hour`, `weekday`, `rolling_mean_2h` and `PULocationID`. We transformed `PULocationID` into `PULocationID_encoded` at a later point using target encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = stats['trip_count']\n",
    "X = stats[['temperature_2m (°C)', 'rain (mm)', 'hour', 'weekday', 'PULocationID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56545c2",
   "metadata": {},
   "source": [
    "#### 5.1.1 Data-Split\n",
    "For this model, we used a data split of 60% training, 20% validation, and 20% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f41d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2898d24-4fb4-4d05-a7a0-5411f280b5d0",
   "metadata": {},
   "source": [
    "#### 5.1.2 Target Encoding\n",
    "To make the `PULocationID` feature usable for modeling, we applied **Target Encoding** by assigning each location ID the average number of trips associated with it.  \n",
    "Importantly, this encoding was performed **after splitting the data** to avoid data leakage from the test set into the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3093f43-0935-4625-a98a-422d9550089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target-Encoding based of Trainingdata\n",
    "means = X_train.assign(trip_count=y_train).groupby('PULocationID')['trip_count'].mean()\n",
    "X_train['PULocationID_encoded'] = X_train['PULocationID'].map(means)\n",
    "X_val['PULocationID_encoded'] = X_val['PULocationID'].map(means)\n",
    "X_test['PULocationID_encoded'] = X_test['PULocationID'].map(means)\n",
    "#filling missing values with global mean\n",
    "global_mean = y_train.mean()\n",
    "X_train['PULocationID_encoded'] = X_train['PULocationID_encoded'].fillna(global_mean)\n",
    "X_val['PULocationID_encoded'] = X_val['PULocationID_encoded'].fillna(global_mean)\n",
    "X_test['PULocationID_encoded'] = X_test['PULocationID_encoded'].fillna(global_mean)\n",
    "# Final Feature-Set (without Original-ID)\n",
    "X_train = X_train.drop(columns=['PULocationID'])\n",
    "X_val = X_val.drop(columns=['PULocationID'])\n",
    "X_test = X_test.drop(columns=['PULocationID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2f0cf",
   "metadata": {},
   "source": [
    "#### 5.1.3 Hyper-Parameter Optimization\n",
    "In order to optimize our hyperparameters, we used the Grid Search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67512a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "estimator = RandomForestRegressor(random_state=42) \n",
    "\n",
    "grid = GridSearchCV( \n",
    "    estimator=estimator,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,    \n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train) \n",
    "print(\"Best R² on validation folds:\", grid.best_score_)\n",
    "print(\"Beste Parameter:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac8603",
   "metadata": {},
   "source": [
    "#### 5.1.4 Model-Training and Testing\n",
    "The model was trained and tested using the hyperparameters identified through grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid.best_estimator_ #Using the best Hyperparameters from our Gridsearch\n",
    "X_full_train = pd.concat([X_train, X_val]) #combining training and validation Data\n",
    "y_full_train = pd.concat([y_train, y_val]) #combining training and validation Data\n",
    "best_rf.fit(X_full_train, y_full_train) #Model is trained on combined training Dataset\n",
    "y_pred = best_rf.predict(X_test) #Trained Model is used, to make a prediction for the Testdata\n",
    "print(\"Finaler R² (Testset):\", r2_score(y_test, y_pred))\n",
    "print(\"Finales MSE (Testset):\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a7f6a",
   "metadata": {},
   "source": [
    "#### 5.1.5 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(range(n), y_test[:n], label='Actual Trip-Counts', linestyle='-', color='blue')\n",
    "plt.plot(range(n), y_pred[:n], label='Predicted Trip-Counts', linestyle='--', color='orange')\n",
    "plt.title(f\"Modelpredictions vs. Actual Trip-Count (First {n} Observations)\")\n",
    "plt.xlabel('Observationindex')\n",
    "plt.ylabel('Trip-Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503bd95",
   "metadata": {},
   "source": [
    "### 5.2 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = TripData_weather.copy()\n",
    "\n",
    "df['hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['weekday'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "\n",
    "trip_counts = df.groupby(['PULocationID', 'hour', 'weekday']).size().reset_index(name='trip_count')\n",
    "\n",
    "weather_avg = df.groupby(['hour', 'weekday']).agg({\n",
    "    'temperature_2m (°C)': 'mean',\n",
    "    'rain (mm)': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "stats = pd.merge(trip_counts, weather_avg, on=['hour', 'weekday'])\n",
    "\n",
    "y = stats['trip_count']\n",
    "X = stats.drop('trip_count', axis=1)\n",
    "\n",
    "X = pd.get_dummies(X, columns=['PULocationID'], drop_first=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Beste Parameter:\", grid_search.best_params_)\n",
    "print(\"Bestes R² auf Validierung (CV):\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- FINAL TEST RESULTS ---\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True trip counts\")\n",
    "plt.ylabel(\"Predicted trip counts\")\n",
    "plt.title(\"True vs Predicted Trip Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d91986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 3],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_grid=param_grid,\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best R² score on validation folds:\", grid_search.best_score_)\n",
    "\n",
    "best_gbr = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_gbr.predict(X_test)\n",
    "print(\"Final R² (Testset):\", r2_score(y_test, y_pred))\n",
    "print(\"Final MSE (Testset):\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True trip counts\")\n",
    "plt.ylabel(\"Predicted trip counts\")\n",
    "plt.title(\"True vs Predicted Trip Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e637be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
